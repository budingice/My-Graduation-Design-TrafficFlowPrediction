import pandas as pd
import csv
import time
import os
import glob
from datetime import datetime, timedelta

def get_absolute_base_time(file_name):
    """
    ä»æ–‡ä»¶åæå–ç»å¯¹æ—¶é—´åŸºå‡†
    æ–‡ä»¶åç¤ºä¾‹: 20181024_d1_0830_0900.csv -> 2018-10-24 08:30:00
    """
    try:
        parts = file_name.split('_')
        date_str = parts[0]      # 20181024
        start_time_str = parts[2] # 0830
        base_dt = datetime.strptime(f"{date_str}{start_time_str}", "%Y%m%d%H%M")
        return base_dt
    except Exception as e:
        print(f" æ–‡ä»¶å {file_name} æ ¼å¼è§£æå¤±è´¥ï¼Œå°†ä½¿ç”¨é»˜è®¤åç§»: {e}")
        return None

def run_batch_parser():
    # --- é…ç½®å‚æ•° ---
    input_folder = 'dataset'  # æ•°æ®æ–‡ä»¶å¤¹
    output_folder = 'processed_data' # å¤„ç†åä¿å­˜çš„æ–‡ä»¶å¤¹
    sampling_rate = 25 # 25Hz -> 1Hz
    
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)

    # è·å–æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰ csv æ–‡ä»¶
    all_files = sorted(glob.glob(os.path.join(input_folder, "*.csv")))
    
    if not all_files:
        print(f"âŒ åœ¨ {input_folder} æ–‡ä»¶å¤¹ä¸‹æ‰¾ä¸åˆ°ä»»ä½• .csv æ–‡ä»¶ã€‚")
        return

    print(f"ğŸš€ å‘ç° {len(all_files)} ä¸ªæ–‡ä»¶ï¼Œå‡†å¤‡å¼€å§‹æ‰¹å¤„ç†...")
    total_start_time = time.time()

    for file_path in all_files:
        file_name = os.path.basename(file_path)
        base_dt = get_absolute_base_time(file_name)
        
        vehicles_list = []
        trajectories_list = []
        
        print(f"\nğŸ“„ æ­£åœ¨è§£æ: {file_name}")
        file_start_time = time.time()

        with open(file_path, 'r', encoding='utf-8') as f:
            reader = csv.reader(f, delimiter=';')
            try:
                header = next(reader)
            except StopIteration:
                continue
            
            for row_idx, row in enumerate(reader):
                row = [x.strip() for x in row if x.strip()]
                if len(row) < 10: continue
                
                track_id = int(row[0])
                vehicles_list.append({
                    'track_id': track_id,
                    'type': row[1],
                    'avg_speed': float(row[3])
                })
                
                dynamic_data = row[10:]
                for i in range(0, len(dynamic_data), 6 * sampling_rate):
                    chunk = dynamic_data[i : i + 6]
                    if len(chunk) == 6:
                        rel_time = float(chunk[5])
                        
                        # æ ¸å¿ƒæ”¹è¿›ï¼šè½¬æ¢ä¸ºç»å¯¹æ—¶é—´
                        # å¦‚æœæ²¡æœ‰åŸºå‡†æ—¶é—´ï¼Œåˆ™ä¿ç•™ç›¸å¯¹æ—¶é—´
                        abs_time = base_dt + timedelta(seconds=rel_time) if base_dt else rel_time
                        
                        trajectories_list.append({
                            'track_id': track_id,
                            'lat': float(chunk[0]),
                            'lon': float(chunk[1]),
                            'speed': float(chunk[2]),
                            'timestamp': abs_time # ä½¿ç”¨ç»å¯¹æ—¶é—´æˆ³
                        })

        # è½¬æ¢ä¸º DataFrame å¹¶ä¿å­˜
        if trajectories_list:
            df_t = pd.DataFrame(trajectories_list)
            output_file = os.path.join(output_folder, file_name.replace('.csv', '.parquet'))
            df_t.to_parquet(output_file, engine='pyarrow')
            
            # åŒæ—¶ä¿å­˜è½¦è¾†å…ƒæ•°æ®ï¼ˆå¯é€‰ï¼‰
            df_v = pd.DataFrame(vehicles_list)
            df_v.to_parquet(output_file.replace('.parquet', '_info.parquet'), engine='pyarrow')
            
            print(f"âœ… {file_name} è§£æå®Œæˆï¼Œè€—æ—¶: {time.time() - file_start_time:.2f}s")
            print(f"ğŸ“Š è½¨è¿¹ç‚¹æ•°: {len(df_t)}")
        else:
            print(f"âš ï¸ {file_name} æœªæå–åˆ°æœ‰æ•ˆè½¨è¿¹æ•°æ®ã€‚")

    print(f"\nâœ¨ æ‰€æœ‰æ–‡ä»¶å¤„ç†å®Œæ¯•ï¼æ€»è€—æ—¶: {time.time() - total_start_time:.2f} ç§’")
    print(f"ğŸ“‚ å¤„ç†åçš„æ•°æ®ä¿å­˜åœ¨: {output_folder}")

if __name__ == "__main__":
    run_batch_parser()