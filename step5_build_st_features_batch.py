import pandas as pd
import numpy as np
import torch
import os
import glob

def build_st_features_batch():
    # --- é…ç½® ---
    input_dir = "path_data"
    output_dir = "model_inputs"
    num_top_paths = 50  # é€‰å–çš„è·¯å¾„èŠ‚ç‚¹æ•°é‡
    time_step_sec = 60  # æ—¶é—´æ­¥é•¿ï¼Œ60ç§’ï¼ˆå¯æ”¹ä¸º10ç§’ä»¥å¢åŠ æ ·æœ¬é‡ï¼‰
    
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    # 1. æ‰«ææ‰€æœ‰è·¯å¾„æ–‡ä»¶
    path_files = sorted(glob.glob(os.path.join(input_dir, "*_paths.parquet")))
    if not path_files:
        print("âŒ æ‰¾ä¸åˆ°è·¯å¾„æ•°æ®ï¼Œè¯·ç¡®è®¤ step4 å·²è¿è¡Œã€‚")
        return
    
    print(f"ğŸš€ å¼€å§‹å¤šæ–‡ä»¶æ‰¹å¤„ç†ï¼Œå…±æ£€æµ‹åˆ° {len(path_files)} ä¸ªç‰‡æ®µ...")

    # 2. å…¨å±€è·¯å¾„åº“æ„å»ºï¼šä»æ‰€æœ‰ç‰‡æ®µä¸­æ‰¾å‡ºæœ€é¢‘ç¹çš„ P æ¡è·¯å¾„
    print("ğŸ” æ­£åœ¨æ‰«æå…¨å±€é«˜é¢‘è·¯å¾„...")
    all_path_series = []
    for f in path_files:
        temp_df = pd.read_parquet(f)
        temp_df['path_tuple'] = temp_df['edge_id'].apply(tuple)
        all_path_series.append(temp_df['path_tuple'])
    
    global_paths = pd.concat(all_path_series).value_counts().head(num_top_paths).index.tolist()
    path_to_idx = {path: i for i, path in enumerate(global_paths)}
    print(f"âœ… å…¨å±€è·¯å¾„åº“æ„å»ºå®Œæˆï¼ŒèŠ‚ç‚¹æ•°: {len(global_paths)}")

    # 3. é€ä¸ªæ–‡ä»¶å¤„ç†ï¼Œç”Ÿæˆæ—¶ç©ºå¼ é‡å—
    st_chunks = []
    
    for file_path in path_files:
        file_name = os.path.basename(file_path)
        df = pd.read_parquet(file_path)
        df['path_tuple'] = df['edge_id'].apply(tuple)
        
        # ç¡®å®šè¯¥ç‰‡æ®µçš„æ—¶é—´èŒƒå›´
        start_t = df['timestamp'].min()
        # å¼ºåˆ¶è®¾ä¸º 15 åˆ†é’Ÿï¼ˆé’ˆå¯¹ pNEUMA æ— äººæœºç»­èˆªç‰¹æ€§ï¼‰
        num_steps = 15 
        
        # åˆå§‹åŒ–å½“å‰ç‰‡æ®µçš„å¼ é‡: (Time, Nodes, Feature)
        X_chunk = np.zeros((num_steps, num_top_paths, 1))
        
        for _, row in df.iterrows():
            if row['path_tuple'] in path_to_idx:
                # è®¡ç®—åˆ†é’Ÿåç§»
                t_idx = int((row['timestamp'] - start_t).total_seconds() // time_step_sec)
                p_idx = path_to_idx[row['path_tuple']]
                if 0 <= t_idx < num_steps:
                    X_chunk[t_idx, p_idx, 0] += 1
        
        st_chunks.append(X_chunk)
        print(f"ğŸ“¦ å·²å¤„ç†ç‰‡æ®µ: {file_name} -> Tensor {X_chunk.shape}")

    # 4. æ„å»ºè·¯å¾„é‚»æ¥çŸ©é˜µ A_path (å…¨å±€å”¯ä¸€)
    print("ğŸ•¸ï¸  æ­£åœ¨æ„å»ºè·¯å¾„é‚»æ¥çŸ©é˜µ...")
    A_path = np.zeros((num_top_paths, num_top_paths))
    for i in range(num_top_paths):
        for j in range(num_top_paths):
            # åŸºäºè·¯å¾„é—´è·¯æ®µé‡å å®šä¹‰ç›¸å…³æ€§
            if set(global_paths[i]) & set(global_paths[j]):
                A_path[i, j] = 1
    
    # 5. ä¿å­˜ç»“æœ
    # æœ€ç»ˆä¿å­˜ä¸ºä¸€ä¸ªåŒ…å«å¤šä¸ªå¼ é‡çš„åˆ—è¡¨ï¼Œè®­ç»ƒæ—¶æ¯ä¸ªå¼ é‡æ˜¯ä¸€ä¸ªç‹¬ç«‹çš„åºåˆ—
    final_data = {
        'x_list': st_chunks,       # List of [15, 50, 1] tensors
        'adj': A_path,             # [50, 50] matrix
        'path_labels': global_paths
    }
    
    output_path = os.path.join(output_dir, "st_batch_data.pt")
    torch.save(final_data, output_path)
    print(f"\nâœ¨ å…¨éƒ¨å®Œæˆï¼ç»“æœå·²ä¿å­˜è‡³: {output_path}")
    print(f"ğŸ“Š æ€»æ ·æœ¬ç‰‡æ®µæ•°: {len(st_chunks)}")

if __name__ == "__main__":
    build_st_features_batch()