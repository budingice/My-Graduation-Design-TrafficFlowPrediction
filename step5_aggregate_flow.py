import pandas as pd
import os
import glob

def aggregate_path_level_flow(interval_min=5):
    input_dir = "path_data"
    output_file = "final_path_flow_results.parquet"
    
    path_files = glob.glob(os.path.join(input_dir, "*_paths.parquet"))
    all_records = []

    print(f"ğŸ“Š æ­£åœ¨èšåˆã€è·¯å¾„çº§ã€‘æµé‡ï¼Œæ—¶é—´æ­¥é•¿: {interval_min} åˆ†é’Ÿ...")

    for file_path in path_files:
        df = pd.read_parquet(file_path)
        
        # 1. è½¬æ¢æ—¶é—´çª—
        df['timestamp'] = pd.to_datetime(df['timestamp'])
        df['time_window'] = df['timestamp'].dt.floor(f'{interval_min}min')

        # 2. å°†åˆ—è¡¨æ ¼å¼çš„ edge_id è½¬æ¢ä¸ºå”¯ä¸€çš„å­—ç¬¦ä¸²è·¯å¾„ (ä¾‹å¦‚ "A -> B -> C")
        # è¿™æ ·ç›¸åŒçš„è·¯å¾„åºåˆ—æ‰èƒ½è¢«åˆ†åˆ°ä¸€ç»„
        df['path_id'] = df['edge_id'].apply(lambda x: " -> ".join(x))

        # 3. æŒ‰ã€æ—¶é—´çª—ã€‘å’Œã€å”¯ä¸€è·¯å¾„IDã€‘è®¡æ•°
        path_counts = df.groupby(['time_window', 'path_id']).size().reset_index(name='path_flow_count')
        all_records.append(path_counts)

    # 4. åˆå¹¶å¹¶æœ€ç»ˆæ±‡æ€»
    final_df = pd.concat(all_records)
    final_df = final_df.groupby(['time_window', 'path_id'])['path_flow_count'].sum().reset_index()

    # 5. ä¿å­˜
    final_df.to_parquet(output_file)
    print(f"âœ… èšåˆå®Œæˆï¼")
    print(f"ç»Ÿè®¡å‡ºå”¯ä¸€è·¯å¾„æ€»æ•°: {final_df['path_id'].nunique()}")
    print(f"æ•°æ®å·²ä¿å­˜è‡³: {output_file}")

if __name__ == "__main__":
    aggregate_path_level_flow(5)